{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omni has 3 types of files:\n",
    "- WhatsApp\n",
    "- Facebook Messenger\n",
    "- Email\n",
    "\n",
    "to be cleansed:\n",
    "\n",
    "- We just need to convert the datetime format and also remove all values \"-\"\n",
    "- remove all null values\n",
    "- convert the datetime column\n",
    "- and the file name should be omni_channel_startdate_enddate\n",
    "- specifically for EMAIL, the messages have to be converted from HTML into text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WhatsApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>From Name</th>\n",
       "      <th>from</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>Agent Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>message</th>\n",
       "      <th>Date Create</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wa_6661ebb11a58d</td>\n",
       "      <td>AB</td>\n",
       "      <td>082226882576</td>\n",
       "      <td>7535</td>\n",
       "      <td></td>\n",
       "      <td>IN</td>\n",
       "      <td># Request From Bot</td>\n",
       "      <td>2024-06-07 00:02:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         session_id From Name          from  agent_id Agent Name Type  \\\n",
       "0  wa_6661ebb11a58d        AB  082226882576      7535              IN   \n",
       "\n",
       "              message         Date Create  \n",
       "0  # Request From Bot 2024-06-07 00:02:41  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path=r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\data check\\new as per 5 June\\omni\\interaction_whatsapp_history.xlsx\"\n",
    "df=pd.read_excel(path)\n",
    "\n",
    "col= ['session_id',\n",
    "'From Name',\n",
    "'from',\n",
    "'agent_id',\n",
    "'Agent Name',\n",
    "'Type',\n",
    "'message',\n",
    "'Date Create']\n",
    "\n",
    "\n",
    "df.replace('NULL', np.nan, inplace=True)\n",
    "df.replace('None', np.nan, inplace=True)\n",
    "df.replace('N/A', np.nan, inplace=True)\n",
    "df.fillna('', inplace=True)\n",
    "df.replace(\"-\", \"\", inplace=True)\n",
    "\n",
    "\n",
    "columns_to_convert = ['Date Create']\n",
    "for column in columns_to_convert:\n",
    "    df[column] = pd.to_datetime(df[column], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "    df[column] = df[column].apply(lambda x: '' if pd.isna(x) else x)\n",
    "    \n",
    "df.drop('Unnamed: 0', axis=1, inplace=True, errors='ignore')\n",
    "startdate = pd.Timestamp(min(df['Date Create']))\n",
    "enddate = pd.Timestamp(max(df['Date Create']))\n",
    "\n",
    "formatted_startdate = startdate.strftime('%Y%m%d')\n",
    "formatted_enddate = enddate.strftime('%Y%m%d')\n",
    "\n",
    "filename = f\"omni_wa_{formatted_startdate}_{formatted_enddate}.csv\"\n",
    "df=df[col]\n",
    "df = df[(df != 0).all(axis=1)]\n",
    "df.to_csv(filename, index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook messenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>From Name</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>Type</th>\n",
       "      <th>message</th>\n",
       "      <th>Date Create</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fm_6661eccaea742</td>\n",
       "      <td>Ismail Fikri</td>\n",
       "      <td>5178</td>\n",
       "      <td>IN</td>\n",
       "      <td>image</td>\n",
       "      <td>2024-06-07 00:07:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         session_id     From Name  agent_id Type message         Date Create\n",
       "0  fm_6661eccaea742  Ismail Fikri      5178   IN   image 2024-06-07 00:07:22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col = ['session_id',\n",
    "'From Name',\n",
    "'agent_id',\n",
    "'Type',\n",
    "'message',\n",
    "'Date Create']\n",
    "\n",
    "path=r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\data check\\new as per 5 June\\omni\\interaction_messenger_history.xlsx\"\n",
    "df=pd.read_excel(path)\n",
    "df.replace('NULL', np.nan, inplace=True)\n",
    "df.replace('None', np.nan, inplace=True)\n",
    "df.replace('N/A', np.nan, inplace=True)\n",
    "df.fillna('', inplace=True)\n",
    "df.replace(\"-\", \"\", inplace=True)\n",
    "\n",
    "columns_to_convert = ['Date Create']\n",
    "for column in columns_to_convert:\n",
    "    df[column] = pd.to_datetime(df[column], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "    df[column] = df[column].apply(lambda x: '' if pd.isna(x) else x)\n",
    "    \n",
    "  \n",
    "df.drop('Unnamed: 0', axis=1, inplace=True, errors='ignore')\n",
    "startdate = pd.Timestamp(min(df['Date Create']))\n",
    "enddate = pd.Timestamp(max(df['Date Create']))\n",
    "\n",
    "formatted_startdate = startdate.strftime('%Y%m%d')\n",
    "formatted_enddate = enddate.strftime('%Y%m%d')\n",
    "\n",
    "filename = f\"omni_messenger_{formatted_startdate}_{formatted_enddate}.csv\"\n",
    "df=df[col]\n",
    "df = df[(df != 0).all(axis=1)]\n",
    "df.to_csv(filename, index=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>From Email</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>Agent Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Date Created</th>\n",
       "      <th>message_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>em_663fa453b84c5</td>\n",
       "      <td>reply@e.ktvu.com</td>\n",
       "      <td>7594</td>\n",
       "      <td></td>\n",
       "      <td>IN</td>\n",
       "      <td>2024-05-12 00:00:56</td>\n",
       "      <td>Cute Alert! Help Name Oakland Zoo's New Giraff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         session_id        From Email  agent_id Agent Name Type  \\\n",
       "0  em_663fa453b84c5  reply@e.ktvu.com      7594              IN   \n",
       "\n",
       "         Date Created                                       message_text  \n",
       "0 2024-05-12 00:00:56  Cute Alert! Help Name Oakland Zoo's New Giraff...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "col = [\n",
    "'session_id',\n",
    "'From Email',\n",
    "'agent_id',\n",
    "'Agent Name',\n",
    "'Type',\n",
    "'message_html',\n",
    "'Date Created']\n",
    "\n",
    "\n",
    "path=r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\data check\\new as per 5 June\\omni\\interaction_email.xlsx\"\n",
    "df=pd.read_excel(path)\n",
    "df.replace('NULL', np.nan, inplace=True)\n",
    "df.replace('None', np.nan, inplace=True)\n",
    "df.replace('N/A', np.nan, inplace=True)\n",
    "df.fillna('', inplace=True)\n",
    "df.replace(\"-\", \"\", inplace=True)\n",
    "\n",
    "columns_to_convert = ['Date Created']\n",
    "for column in columns_to_convert:\n",
    "    df[column] = pd.to_datetime(df[column], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "    df[column] = df[column].apply(lambda x: '' if pd.isna(x) else x)\n",
    "\n",
    "\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True, errors='ignore')\n",
    "startdate = pd.Timestamp(min(df['Date Created']))\n",
    "enddate = pd.Timestamp(max(df['Date Created']))\n",
    "\n",
    "formatted_startdate = startdate.strftime('%Y%m%d')\n",
    "formatted_enddate = enddate.strftime('%Y%m%d')\n",
    "\n",
    "filename = f\"omni_email_{formatted_startdate}_{formatted_enddate}.csv\"\n",
    "df=df[col]\n",
    "df = df[(df != 0).all(axis=1)]\n",
    "def html_to_text(html):\n",
    "    if pd.isna(html):\n",
    "        return \"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "df['message_text'] = df['message_html'].apply(html_to_text)\n",
    "df = df.drop(columns=['message_html'])\n",
    "df.to_csv(filename, index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\AppData\\Local\\Temp\\ipykernel_3228\\2792447895.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna('', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>from_name</th>\n",
       "      <th>from</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>action_type</th>\n",
       "      <th>message</th>\n",
       "      <th>date_create</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ss_e21bBEGXtct</td>\n",
       "      <td></td>\n",
       "      <td>81545308978</td>\n",
       "      <td></td>\n",
       "      <td>IN</td>\n",
       "      <td>Sudah kakak . Tapi ngga di proses² sampai seka...</td>\n",
       "      <td>2024-04-01 00:03:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       session_id from_name         from agent_id action_type  \\\n",
       "0  ss_e21bBEGXtct            81545308978                   IN   \n",
       "\n",
       "                                             message         date_create  \n",
       "0  Sudah kakak . Tapi ngga di proses² sampai seka... 2024-04-01 00:03:57  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path=r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\data check\\new as per 5 June\\omni\\interaction_sms_history.xlsx\"\n",
    "df=pd.read_excel(path)\n",
    "\n",
    "col= ['session_id',\n",
    "'from_name',\n",
    "'from',\n",
    "'agent_id',\n",
    "'action_type',\n",
    "'message',\n",
    "'date_create']\n",
    "\n",
    "df.replace('NULL', np.nan, inplace=True)\n",
    "df.replace('None', np.nan, inplace=True)\n",
    "df.replace('N/A', np.nan, inplace=True)\n",
    "df.fillna('', inplace=True)\n",
    "df.replace(\"-\", \"\", inplace=True)\n",
    "\n",
    "columns_to_convert = ['date_create']\n",
    "for column in columns_to_convert:\n",
    "    df[column] = pd.to_datetime(df[column], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "    df[column] = df[column].apply(lambda x: '' if pd.isna(x) else x)\n",
    "    \n",
    "  \n",
    "df.drop('Unnamed: 0', axis=1, inplace=True, errors='ignore')\n",
    "startdate = pd.Timestamp(min(df['date_create']))\n",
    "enddate = pd.Timestamp(max(df['date_create']))\n",
    "\n",
    "formatted_startdate = startdate.strftime('%Y%m%d')\n",
    "formatted_enddate = enddate.strftime('%Y%m%d')\n",
    "\n",
    "filename = f\"omni_sms_{formatted_startdate}_{formatted_enddate}.csv\"\n",
    "df=df[col]\n",
    "df = df[(df != 0).all(axis=1)]\n",
    "df.to_csv(filename, index=False)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For SQL files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FB SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid dates in column date_create:\n",
      "                                                       id  \\\n",
      "190                                                  191   \n",
      "198    199, 'fm_5bf52b55b60d5', '1947363098664914~88a...   \n",
      "203    204, 'fm_5bf52b55b60d5', '1947363098664914~88a...   \n",
      "306    307, 'fm_5bf53d35921be', '1922562317821204~88a...   \n",
      "590    591, 'fm_5bf55ceeeeb11', '2157474787630041~88a...   \n",
      "...                                                  ...   \n",
      "59100  59101, 'fm_5c3197aadebe1', '2240044126013783~8...   \n",
      "59507  59509, 'fm_5c3215ca1eeb9', '1815452235233135~8...   \n",
      "59792  59775, 'fm_5c32b4c3ae19c', '2185371724818306~8...   \n",
      "60221  60240, 'fm_5c3302f84507a', '970714056385837~88...   \n",
      "60227  60262, 'fm_5c3302f84507a', '970714056385837~88...   \n",
      "\n",
      "                                              session_id  \\\n",
      "190                                     fm_5bf52b55b60d5   \n",
      "198                                                    0   \n",
      "203                                                    0   \n",
      "306                                                 text   \n",
      "590                                                 text   \n",
      "...                                                  ...   \n",
      "59100                                               text   \n",
      "59507                                               text   \n",
      "59792  we\\'re here to help. Let us know what we can d...   \n",
      "60221  mau tanya ni bisa tidak y buat internet bankin...   \n",
      "60227                                               text   \n",
      "\n",
      "                                                 conv_id  \\\n",
      "190    1947363098664914~88a0337b-e7af-4ef6-95a5-e1798...   \n",
      "198                                                   IN   \n",
      "203                                                   IN   \n",
      "306                                                        \n",
      "590                                                        \n",
      "...                                                  ...   \n",
      "59100                                                      \n",
      "59507                                                      \n",
      "59792                                               text   \n",
      "60221                                               text   \n",
      "60227                                                      \n",
      "\n",
      "                                                    from  \\\n",
      "190                                     1947363098664914   \n",
      "198    iaa sudah jelas, cuma saya belum punya tabunga...   \n",
      "203                    terimakasih sudah memberi info:-)   \n",
      "306                                  2018-11-21 18:14:25   \n",
      "590                                  2018-11-21 20:37:19   \n",
      "...                                                  ...   \n",
      "59100                                2019-01-06 12:52:42   \n",
      "59507                                2019-01-06 21:53:19   \n",
      "59792                                               NULL   \n",
      "60221                                                      \n",
      "60227                                2019-01-07 15:07:25   \n",
      "\n",
      "                                               from_name  \\\n",
      "190    Raveno Somantri K\\'Dua Veno', 0, 'IN', 'Raveno...   \n",
      "198                                                 text   \n",
      "203                                                 text   \n",
      "306                                                    0   \n",
      "590                                                    0   \n",
      "...                                                  ...   \n",
      "59100                                                  0   \n",
      "59507                                                  0   \n",
      "59792                                2019-01-07 10:10:47   \n",
      "60221                                2019-01-07 14:42:48   \n",
      "60227                                                  0   \n",
      "\n",
      "                                                agent_id          action_type  \\\n",
      "190    saat ini saya hanya bisa memberikan info produ...                 text   \n",
      "198                                                       2018-11-21 16:59:41   \n",
      "203                                                       2018-11-21 17:01:30   \n",
      "306                                                    0                 NULL   \n",
      "590                                                    0                 NULL   \n",
      "...                                                  ...                  ...   \n",
      "59100                                                  0                 NULL   \n",
      "59507                                                  0                 NULL   \n",
      "59792                                                  0                    0   \n",
      "60221                                                  0                    0   \n",
      "60227                                                  0                 NULL   \n",
      "\n",
      "      message         message_type                media date_create  \\\n",
      "190            2018-11-21 16:54:29                    0           0   \n",
      "198         0                    0                 NULL        NULL   \n",
      "203         0                    0                 NULL        NULL   \n",
      "306      NULL  2018-11-21 18:14:29                 NULL        NULL   \n",
      "590      NULL  2018-11-21 20:37:23                 NULL        NULL   \n",
      "...       ...                  ...                  ...         ...   \n",
      "59100    NULL  2019-01-06 12:52:49                 NULL        NULL   \n",
      "59507    NULL  2019-01-06 21:53:26                 NULL        NULL   \n",
      "59792    NULL                 NULL  2019-01-07 10:10:54        NULL   \n",
      "60221    NULL                 NULL  2019-01-07 14:42:55        NULL   \n",
      "60227    NULL  2019-01-07 15:07:32                 NULL        NULL   \n",
      "\n",
      "                      read  send        response_time   upd   lup  \n",
      "190                   NULL  NULL  2018-11-21 16:54:33  NULL  NULL  \n",
      "198    2018-11-21 16:59:45  NULL                 NULL  NULL   nan  \n",
      "203    2018-11-21 17:01:34  NULL                 NULL  NULL   nan  \n",
      "306                   NULL   nan                  nan   nan   nan  \n",
      "590                   NULL   nan                  nan   nan   nan  \n",
      "...                    ...   ...                  ...   ...   ...  \n",
      "59100                 NULL   nan                  nan   nan   nan  \n",
      "59507                 NULL   nan                  nan   nan   nan  \n",
      "59792                 NULL  NULL                  nan   nan   nan  \n",
      "60221                 NULL  NULL                  nan   nan   nan  \n",
      "60227                 NULL   nan                  nan   nan   nan  \n",
      "\n",
      "[532 rows x 16 columns]\n",
      "Invalid dates in column response_time:\n",
      "           id        session_id  \\\n",
      "0          1  fm_5bf517f3a8834   \n",
      "1          2  fm_5bf517fa8f83c   \n",
      "2          3  fm_5bf517f3a8834   \n",
      "3          4  fm_5bf517f3a8834   \n",
      "4          5  fm_5bf517f3a8834   \n",
      "...      ...               ...   \n",
      "60691  60700  fm_5c339af9551d5   \n",
      "60692  60701  fm_5c339af9551d5   \n",
      "60693  60702  fm_5c339af9551d5   \n",
      "60694  60703  fm_5c339af9551d5   \n",
      "60695  60704  fm_5c33bf19afed7   \n",
      "\n",
      "                                                 conv_id              from  \\\n",
      "0      2053788084660579~88a0337b-e7af-4ef6-95a5-e1798...  2053788084660579   \n",
      "1      1666450473460874~88a0337b-e7af-4ef6-95a5-e1798...  1666450473460874   \n",
      "2      2053788084660579~88a0337b-e7af-4ef6-95a5-e1798...  2053788084660579   \n",
      "3      2053788084660579~88a0337b-e7af-4ef6-95a5-e1798...  2053788084660579   \n",
      "4      2053788084660579~88a0337b-e7af-4ef6-95a5-e1798...  2053788084660579   \n",
      "...                                                  ...               ...   \n",
      "60691  1989847871133441~88a0337b-e7af-4ef6-95a5-e1798...  1989847871133441   \n",
      "60692  1989847871133441~88a0337b-e7af-4ef6-95a5-e1798...                     \n",
      "60693  1989847871133441~88a0337b-e7af-4ef6-95a5-e1798...  1989847871133441   \n",
      "60694  1989847871133441~88a0337b-e7af-4ef6-95a5-e1798...                     \n",
      "60695  2573340822706497~88a0337b-e7af-4ef6-95a5-e1798...  2573340822706497   \n",
      "\n",
      "                  from_name agent_id action_type  \\\n",
      "0              Adie Suryana        0          IN   \n",
      "1         Yustika Sipahutar        0          IN   \n",
      "2              Adie Suryana        0          IN   \n",
      "3              Adie Suryana        0          IN   \n",
      "4              Adie Suryana        0          IN   \n",
      "...                     ...      ...         ...   \n",
      "60691     Kurniawan Landack        0          IN   \n",
      "60692  Erlangga Kurniawan Y      178         OUT   \n",
      "60693     Kurniawan Landack        0          IN   \n",
      "60694  Erlangga Kurniawan Y      178         OUT   \n",
      "60695             Nunung Oi        0          IN   \n",
      "\n",
      "                                                 message message_type media  \\\n",
      "0      Adie Suryana:Maaf pa sarat\\\" Buat kartu kredit...         text         \n",
      "1      Yustika Sipahutar:Mau tanya kalau atm kadaluar...         text         \n",
      "2                                                     Ok         text         \n",
      "3      Buku tabungan saya hilang buku tabungan nya sa...         text         \n",
      "4                      Saya sekarang domisili di jakarta         text         \n",
      "...                                                  ...          ...   ...   \n",
      "60691        Supaya internet banking saya Bisa digunakan         text         \n",
      "60692  Mohon maaf registrasi ulang layanan Internet B...         text  NULL   \n",
      "60693  Oke Terima kasih waktunya sudah membantu.... ?...         text         \n",
      "60694  Dengan senang hati. Terima kasih telah menghub...         text  NULL   \n",
      "60695  Nunung Oi:Lewat info mutasi katanya bisa ya..\\...         text         \n",
      "\n",
      "               date_create read send response_time   upd                  lup  \n",
      "0      2018-11-21 15:31:47    0    0          NULL  NULL  2018-11-21 15:31:51  \n",
      "1      2018-11-21 15:31:54    0    0          NULL  NULL  2018-11-21 15:31:58  \n",
      "2      2018-11-21 15:32:09    0    0          NULL  NULL  2018-11-21 15:32:12  \n",
      "3      2018-11-21 15:32:48    0    0          NULL  NULL  2018-11-21 15:32:52  \n",
      "4      2018-11-21 15:32:57    0    0          NULL  NULL  2018-11-21 15:33:01  \n",
      "...                    ...  ...  ...           ...   ...                  ...  \n",
      "60691  2019-01-08 01:49:11    0    0          NULL  NULL  2019-01-08 01:49:18  \n",
      "60692  2019-01-08 01:51:04    0    0          NULL  NULL  2019-01-08 01:51:07  \n",
      "60693  2019-01-08 01:52:40    0    0          NULL  NULL  2019-01-08 01:52:47  \n",
      "60694  2019-01-08 01:53:15    0    0          NULL  NULL  2019-01-08 01:53:23  \n",
      "60695  2019-01-08 04:05:29    0    0          NULL  NULL  2019-01-08 04:05:36  \n",
      "\n",
      "[60469 rows x 16 columns]\n",
      "Corrected parsed data saved to C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\data check\\new as per 5 June\\omni_fb_sql_20181121_20190108.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "expected_columns = ['id', 'session_id', 'conv_id', 'from', 'from_name', 'agent_id', 'action_type', 'message', 'message_type', 'media', 'date_create', 'read', 'send', 'response_time', 'upd', 'lup']\n",
    "\n",
    "# Function to parse SQL insert statements with enhanced handling\n",
    "def parse_sql_inserts(sql_data):\n",
    "    insert_pattern = re.compile(r\"INSERT INTO `interaction_messenger_history` VALUES \\((?P<values>.+?)\\);\", re.DOTALL)\n",
    "    matches = insert_pattern.findall(sql_data)\n",
    "\n",
    "    data = []\n",
    "    for values_str in matches:\n",
    "        values = re.split(r\",(?=(?:[^\\']*\\'[^\\']*\\')*[^\\']*$)\", values_str)\n",
    "        values = [val.strip().strip(\"'\") for val in values]\n",
    "        values = [val.replace(\"\\\\n\", \"\\n\").replace('\\\"', '\"') for val in values]  # Handle newline characters and escape sequences\n",
    "        data.append(dict(zip(expected_columns, values)))\n",
    "\n",
    "    return data\n",
    "\n",
    "sql_file_path = r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\data check\\new as per 5 June\\omni\\interaction_messenger_history.sql\"\n",
    "with open(sql_file_path, 'r', encoding='utf-8') as file:\n",
    "    sql_data = file.read()\n",
    "\n",
    "\n",
    "parsed_data = parse_sql_inserts(sql_data)\n",
    "\n",
    "\n",
    "df_sql = pd.DataFrame(parsed_data)\n",
    "\n",
    "\n",
    "for col in expected_columns:\n",
    "    if col not in df_sql.columns:\n",
    "        df_sql[col] = None\n",
    "\n",
    "# Reorder columns to match the expected output\n",
    "df_sql = df_sql[expected_columns]\n",
    "\n",
    "\n",
    "df_sql.drop('Unnamed: 0', axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "for col in df_sql.columns:\n",
    "    df_sql[col] = df_sql[col].astype(str, errors='ignore')\n",
    "\n",
    "\n",
    "def is_valid_date_format(date_str):\n",
    "    try:\n",
    "        pd.to_datetime(date_str)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "date_columns = ['date_create', 'response_time']\n",
    "for col in date_columns:\n",
    "    invalid_dates = df_sql[~df_sql[col].apply(is_valid_date_format)]\n",
    "    print(f\"Invalid dates in column {col}:\\n\", invalid_dates)\n",
    "\n",
    "\n",
    "df_sql.replace(['NULL', 'None', 'N/A', '0'], np.nan, inplace=True)\n",
    "df_sql.fillna('', inplace=True)\n",
    "\n",
    "\n",
    "df_sql['date_create'] = pd.to_datetime(df_sql['date_create'], errors='coerce')\n",
    "df_sql['response_time'] = pd.to_datetime(df_sql['response_time'], errors='coerce')\n",
    "\n",
    "\n",
    "startdate = df_sql['date_create'].min()\n",
    "enddate = df_sql['date_create'].max()\n",
    "\n",
    "formatted_startdate = startdate.strftime('%Y%m%d')\n",
    "formatted_enddate = enddate.strftime('%Y%m%d')\n",
    "\n",
    "filename = f\"omni_fb_sql_{formatted_startdate}_{formatted_enddate}.csv\"\n",
    "\n",
    "corrected_csv_path = rf\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\data check\\new as per 5 June\\{filename}\"\n",
    "df_sql.to_csv(corrected_csv_path, index=False)\n",
    "print(f\"Corrected parsed data saved to {corrected_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zendesk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\AppData\\Local\\Temp\\ipykernel_3228\\2839367595.py:46: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(apply_mapping)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "directory_path = r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\data check\\new as per 5 June\\test_zendesk\"\n",
    "output_folder = r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\new as per 5 June\\test zendesk\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "file_list = [f for f in os.listdir(directory_path) if f.endswith('.csv')]\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "    with open(file_path, 'r', newline='') as file:\n",
    "        reader = csv.reader(file, delimiter=',', quotechar='\"')\n",
    "        rows = [row for row in reader]\n",
    "\n",
    "    split_rows = []\n",
    "    for row in rows:\n",
    "        split_row = row[0].split(',') + row[1:]\n",
    "        split_rows.append(split_row)\n",
    "\n",
    "    df = pd.DataFrame(split_rows[1:], columns=split_rows[0])\n",
    "\n",
    "    df.columns = df.columns.str.replace('\"', '')\n",
    "    df = df.replace('\"', '', regex=True)\n",
    "    date_columns= ['Requester created - Timestamp','Ticket created - Timestamp','Ticket solved - Timestamp']\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col]).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df=df.drop('Tickets',axis=1)\n",
    "\n",
    "    df = df[df['Ticket channel'] != 'Instagram Direct']\n",
    "\n",
    "    mapping_sets = [\n",
    "        {'Any channel': 'Instagram'}\n",
    "    ]\n",
    "    mapping = {}\n",
    "    for mapping_set in mapping_sets:\n",
    "        mapping.update(mapping_set)\n",
    "\n",
    "\n",
    "    def apply_mapping(value):\n",
    "        return mapping.get(value, value)\n",
    "    df = df.applymap(apply_mapping)\n",
    "\n",
    "    startdate = pd.Timestamp(min(df['Ticket created - Timestamp']))\n",
    "    enddate = pd.Timestamp(max(df['Ticket created - Timestamp']))\n",
    "    formatted_startdate = startdate.strftime('%Y%m%d')\n",
    "    formatted_enddate = enddate.strftime('%Y%m%d')\n",
    "\n",
    "    filename = f\"zendesk_{formatted_startdate}_{formatted_enddate}_{file_name}\"\n",
    "    output_file_path = os.path.join(output_folder, filename)\n",
    "    df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zendesk : How to Extract the bricare_id (not used anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Details</th>\n",
       "      <th>bricare_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB001</td>\n",
       "      <td>TT Zendesk: 2533068</td>\n",
       "      <td>2533068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTB002</td>\n",
       "      <td>TT Zendesk  Ticket #2480057</td>\n",
       "      <td>2480057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTB003</td>\n",
       "      <td>TT Zendesk  #2483681</td>\n",
       "      <td>2483681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTB004</td>\n",
       "      <td>Zendesk : Ticket #2477717</td>\n",
       "      <td>2477717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTB005</td>\n",
       "      <td>TT Zendesk  Ticket #2485228</td>\n",
       "      <td>2485228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticket ID                      Details bricare_id\n",
       "0    TTB001          TT Zendesk: 2533068    2533068\n",
       "1    TTB002  TT Zendesk  Ticket #2480057    2480057\n",
       "2    TTB003         TT Zendesk  #2483681    2483681\n",
       "3    TTB004    Zendesk : Ticket #2477717    2477717\n",
       "4    TTB005  TT Zendesk  Ticket #2485228    2485228"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Ticket ID': ['TTB001', 'TTB002', 'TTB003', 'TTB004', 'TTB005'],\n",
    "    'Details': [\n",
    "        'TT Zendesk: 2533068',\n",
    "        'TT Zendesk  Ticket #2480057',\n",
    "        'TT Zendesk  #2483681',\n",
    "        'Zendesk : Ticket #2477717',\n",
    "        'TT Zendesk  Ticket #2485228'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# path=r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\output\\exp_51.csv\"\n",
    "# df=pd.read_csv(path)\n",
    "\n",
    "\n",
    "def extract_number(detail):\n",
    "    match = re.search(r'Zendesk.*?(\\d{7})', detail)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "df['bricare_id'] = df['Details'].apply(extract_number)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
