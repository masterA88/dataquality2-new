{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attachment generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_exact_size_file(file_path, size_mb):\n",
    "    # Calculate the exact size in bytes\n",
    "    size_bytes = size_mb * 1024 * 1024\n",
    "\n",
    "    # Open the file in write binary ('wb') mode\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.seek(size_bytes - 1)  # Move to the position one byte before the desired size\n",
    "        file.write(b'\\0')  # Write a single zero byte at this position\n",
    "\n",
    "def generate_files(directory_path, excel_filename, pdf_filename, target_size_mb):\n",
    "    # Ensure the directory ends with a slash\n",
    "    if not directory_path.endswith('/'):\n",
    "        directory_path += '/'\n",
    "\n",
    "    # Generate exact-sized Excel and PDF files\n",
    "    create_exact_size_file(directory_path + excel_filename, target_size_mb)\n",
    "    create_exact_size_file(directory_path + pdf_filename, target_size_mb)\n",
    "\n",
    "    print(f'Generated Excel file at {directory_path + excel_filename} with size exactly {target_size_mb} MB')\n",
    "    print(f'Generated PDF file at {directory_path + pdf_filename} with size exactly {target_size_mb} MB')\n",
    "\n",
    "# Set the directory where files will be saved\n",
    "directory_path = \"/Users/ikawahyuni/dataquality/dummy_files\"\n",
    "\n",
    "# Set filenames and target size\n",
    "generate_files(directory_path, 'dummy_15mb.xlsx', 'dummy_15mb.pdf', 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Excel file at /Users/ikawahyuni/dataquality/dummy_files/dummy_14mb.xlsx with size exactly 14 MB\n",
      "Generated PDF file at /Users/ikawahyuni/dataquality/dummy_files/dummy_14mb.pdf with size exactly 14 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_exact_size_file(file_path, size_mb):\n",
    "    # Calculate the exact size in bytes\n",
    "    size_bytes = size_mb * 1024 * 1024\n",
    "\n",
    "    # Open the file in write binary ('wb') mode\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.seek(size_bytes - 1)  # Move to the position one byte before the desired size\n",
    "        file.write(b'\\0')  # Write a single zero byte at this position\n",
    "\n",
    "def generate_files(directory_path, excel_filename, pdf_filename, target_size_mb):\n",
    "    # Ensure the directory ends with a slash\n",
    "    if not directory_path.endswith('/'):\n",
    "        directory_path += '/'\n",
    "\n",
    "    # Generate exact-sized Excel and PDF files\n",
    "    create_exact_size_file(directory_path + excel_filename, target_size_mb)\n",
    "    create_exact_size_file(directory_path + pdf_filename, target_size_mb)\n",
    "\n",
    "    print(f'Generated Excel file at {directory_path + excel_filename} with size exactly {target_size_mb} MB')\n",
    "    print(f'Generated PDF file at {directory_path + pdf_filename} with size exactly {target_size_mb} MB')\n",
    "\n",
    "# Set the directory where files will be saved\n",
    "directory_path = \"/Users/ikawahyuni/dataquality/dummy_files\"\n",
    "\n",
    "# Set filenames and target size (change from 15 to 14)\n",
    "generate_files(directory_path, 'dummy_14mb.xlsx', 'dummy_14mb.pdf', 14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maximum size limit of 10,485,760 bytes (10 MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Excel file at D:\\dataquality\\dummy_files/dummy.xlsx with size up to 10 MB\n",
      "Generated PDF file at D:\\dataquality\\dummy_files/dummy.pdf with size up to 10 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_exact_size_file(file_path, size_mb):\n",
    "    # Maximum size in bytes (10 MB)\n",
    "    max_size_bytes = 9485760\n",
    "\n",
    "    # Calculate the desired size in bytes\n",
    "    size_bytes = size_mb * 1024 * 1024\n",
    "\n",
    "    # Adjust size if it exceeds the maximum allowed\n",
    "    if size_bytes > max_size_bytes:\n",
    "        size_bytes = max_size_bytes\n",
    "\n",
    "    # Open the file in write binary ('wb') mode\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.seek(size_bytes - 1)  # Move to the position one byte before the desired size\n",
    "        file.write(b'\\0')  # Write a single zero byte at this position\n",
    "\n",
    "def generate_files(directory_path, excel_filename, pdf_filename, target_size_mb):\n",
    "    # Ensure the directory ends with a slash\n",
    "    if not directory_path.endswith('/'):\n",
    "        directory_path += '/'\n",
    "\n",
    "    # Generate exact-sized Excel and PDF files\n",
    "    create_exact_size_file(directory_path + excel_filename, target_size_mb)\n",
    "    create_exact_size_file(directory_path + pdf_filename, target_size_mb)\n",
    "\n",
    "    actual_size_mb = min(target_size_mb, 10)  # Limit the reported size to 10 MB max\n",
    "    print(f'Generated Excel file at {directory_path + excel_filename} with size up to {actual_size_mb} MB')\n",
    "    print(f'Generated PDF file at {directory_path + pdf_filename} with size up to {actual_size_mb} MB')\n",
    "\n",
    "# Set the directory where files will be saved\n",
    "directory_path = \"D:\\dataquality\\dummy_files\"\n",
    "\n",
    "# Set filenames and target size (e.g., 12 MB would be reduced to 10 MB)\n",
    "generate_files(directory_path, 'dummy.xlsx', 'dummy.pdf', 12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool to collect all tickets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted ReportTest.zip to D:\\Salesforce\\archive\\dataquality\\Tool for attachments\\ReportTest\n",
      "Data from D:\\Salesforce\\archive\\dataquality\\Tool for attachments\\ReportTest\\ReportTest.arx saved to CSV at D:\\Salesforce\\archive\\dataquality\\Tool for attachments\\ReportTest_files_info.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import rarfile  # pip install rarfile\n",
    "import pandas as pd\n",
    "\n",
    "def extract_and_process_files(directory):\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        extract_path = os.path.join(directory, filename[:-4]) \n",
    "\n",
    "   \n",
    "        if filename.endswith(\".zip\"):\n",
    "            with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_path)\n",
    "                print(f\"Extracted {filename} to {extract_path}\")\n",
    "        elif filename.endswith(\".rar\"):\n",
    "            with rarfile.RarFile(filepath, 'r') as rar_ref:\n",
    "                rar_ref.extractall(extract_path)\n",
    "                print(f\"Extracted {filename} to {extract_path}\")\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    " \n",
    "        report_file_path = find_report_file(extract_path)\n",
    "        if report_file_path:\n",
    "            df = create_dataframe_from_file(report_file_path, extract_path)\n",
    "            csv_path = os.path.join(directory, filename[:-4] + '_files_info.csv')\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(f\"Data from {report_file_path} saved to CSV at {csv_path}\")\n",
    "        else:\n",
    "            print(f\"No 'ReportTest.arx' found in {extract_path}\")\n",
    "\n",
    "def find_report_file(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == 'ReportTest.arx':\n",
    "                return os.path.join(root, file)\n",
    "    return None\n",
    "\n",
    "def create_dataframe_from_file(file_path, extract_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    titles = []\n",
    "    descriptions = []\n",
    "    version_data = []\n",
    "    first_publish_location_ids = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"DATA\"):\n",
    "            parts = line.strip().split('\"')\n",
    "            ticket_number = parts[1].strip()\n",
    "            file_name = parts[3].strip().partition(' ')[2]  # Extracting everything after \"1 \"\n",
    "\n",
    "            full_path = os.path.join(extract_path, file_name)\n",
    "\n",
    "            titles.append(file_name)\n",
    "            descriptions.append(\"\")\n",
    "            version_data.append(full_path)\n",
    "            first_publish_location_ids.append(ticket_number)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Description': descriptions,\n",
    "        'VersionData': version_data,\n",
    "        'FirstPublishLocationId': first_publish_location_ids\n",
    "    })\n",
    "\n",
    "\n",
    "directory_path = r'D:\\Salesforce\\archive\\dataquality\\Tool for attachments'\n",
    "extract_and_process_files(directory_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool to collect all tickets 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Report(6).zip to D:\\Python2\\Attachment\\Report(6)\n",
      "Converted 20240727_231535_160.heic to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\20240727_231535_160..zip\n",
      "Converted 6e929343-c3a9-4de4-b96f-ba7c8f45cf51_640.jfif to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\6e929343-c3a9-4de4-b96f-ba7c8f45cf51_640..zip\n",
      "Converted a20983e5-4925-427f-a525-d2739548a59e+-+M.+Abdan+Alkhasbi_759.jfif to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\a20983e5-4925-427f-a525-d2739548a59e+-+M.+Abdan+Alkhasbi_759..zip\n",
      "Converted ADI REMANTO_100724_897.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\ADI REMANTO_100724_897.zip\n",
      "Converted AGUSTINUS TANNOS_150724_665.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\AGUSTINUS TANNOS_150724_665.zip\n",
      "Converted ANDANG TJAHJANTOK_150724_885.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\ANDANG TJAHJANTOK_150724_885.zip\n",
      "Converted ANDI HARTONO_wa150724_491.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\ANDI HARTONO_wa150724_491.zip\n",
      "Converted cecilia perubahan no rek_975.rar to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\cecilia perubahan no rek_975.zip\n",
      "Converted CHRISTIAN SETIAWAN DOLOKSARIBU_150224_924.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\CHRISTIAN SETIAWAN DOLOKSARIBU_150224_924.zip\n",
      "Converted CHRISTIAN SETIAWAN DOLOKSARIBU_150324_925.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\CHRISTIAN SETIAWAN DOLOKSARIBU_150324_925.zip\n",
      "Converted CHRISTIAN SETIAWAN DOLOKSARIBU_150424_926.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\CHRISTIAN SETIAWAN DOLOKSARIBU_150424_926.zip\n",
      "Converted DEA JANE SUNGKONO_150624_576.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\DEA JANE SUNGKONO_150624_576.zip\n",
      "Converted DEA JANE SUNGKONO_150724_577.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\DEA JANE SUNGKONO_150724_577.zip\n",
      "Converted DESSY ROSMARIA_100724_517.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\DESSY ROSMARIA_100724_517.zip\n",
      "Converted ERI SOSIALISMAN_150624_574.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\ERI SOSIALISMAN_150624_574.zip\n",
      "Converted ERIK AZARYA ERLAN_200724_561.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\ERIK AZARYA ERLAN_200724_561.zip\n",
      "Converted FADLI HAQIQI MAGHRIBI_150724_600.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\FADLI HAQIQI MAGHRIBI_150724_600.zip\n",
      "Converted faf6b70c-8af8-441a-9864-8d8c1b336bae_641.jfif to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\faf6b70c-8af8-441a-9864-8d8c1b336bae_641..zip\n",
      "Converted FANI SYAHRIAL R_250624_550.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\FANI SYAHRIAL R_250624_550.zip\n",
      "Converted FANI SYAHRIAL R_250724_551.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\FANI SYAHRIAL R_250724_551.zip\n",
      "Converted GONAWAN EFENDY_020724_542.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\GONAWAN EFENDY_020724_542.zip\n",
      "Converted HANDY PRADHITYA TJHAN_150724_883.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\HANDY PRADHITYA TJHAN_150724_883.zip\n",
      "Converted hartono golam autodebet_987.rar to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\hartono golam autodebet_987.zip\n",
      "Converted haru no hp_990.rar to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\haru no hp_990.zip\n",
      "Converted JENNI MONALISA NABABAN_150724_899.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\JENNI MONALISA NABABAN_150724_899.zip\n",
      "Converted KRISTIANA SATIO_100724_572.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\KRISTIANA SATIO_100724_572.zip\n",
      "Converted MARGANDATB SITUMORANG_150724_904.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\MARGANDATB SITUMORANG_150724_904.zip\n",
      "Converted NEW_REKENING_KORAN_ONLINE_323401019590537_2024-07-28_2024-07-29_00343994.pdf_429.crdownload to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\NEW_REKENING_KORAN_ONLINE_323401019590537_2024-07-28_2024-07-29_00343994.pdf_429.crdown.zip\n",
      "Converted NEW_REKENING_KORAN_ONLINE_738701011779538_2024-07-25_2024-07-25_00362082.pdf_820.crdownload to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\NEW_REKENING_KORAN_ONLINE_738701011779538_2024-07-25_2024-07-25_00362082.pdf_820.crdown.zip\n",
      "Converted NIKEN NOVIANTY RISDIANASARI_020624_543.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\NIKEN NOVIANTY RISDIANASARI_020624_543.zip\n",
      "Converted RIDO TANAIR_100724_888.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RIDO TANAIR_100724_888.zip\n",
      "Converted RIKA ANDINI_150524_940.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RIKA ANDINI_150524_940.zip\n",
      "Converted RIKA ANDINI_150624_941.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RIKA ANDINI_150624_941.zip\n",
      "Converted RIKA ANDINI_150724_945.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RIKA ANDINI_150724_945.zip\n",
      "Converted RMOCHAMAD GANDHANI_150724_534.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RMOCHAMAD GANDHANI_150724_534.zip\n",
      "Converted RUDY YUWONO_plt150724_514.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RUDY YUWONO_plt150724_514.zip\n",
      "Converted RUDY YUWONO_visa150724_513.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RUDY YUWONO_visa150724_513.zip\n",
      "Converted SURYA PURNAMA TJENG_100724_485.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\SURYA PURNAMA TJENG_100724_485.zip\n",
      "Converted SYIFA ALAINA MARICAR_150624_563.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\SYIFA ALAINA MARICAR_150624_563.zip\n",
      "Converted SYIFA ALAINA MARICAR_150724_571.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\SYIFA ALAINA MARICAR_150724_571.zip\n",
      "Converted TEK SUYANTO_200724_508.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\TEK SUYANTO_200724_508.zip\n",
      "Converted THERESIA_150724_532.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\THERESIA_150724_532.zip\n",
      "Converted TITIN NURLAILA_170724_670.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\TITIN NURLAILA_170724_670.zip\n",
      "Converted TRI PANGESTU ADI NAGARA_170724_591.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\TRI PANGESTU ADI NAGARA_170724_591.zip\n",
      "Converted YUNITA SARI DEWI_150424_906.htm to D:\\Python2\\Attachment\\Report(6)\\Report(6)\\YUNITA SARI DEWI_150424_906.zip\n",
      "Converted ._20240727_231535_160.heic to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._20240727_231535_160..zip\n",
      "Converted ._6e929343-c3a9-4de4-b96f-ba7c8f45cf51_640.jfif to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._6e929343-c3a9-4de4-b96f-ba7c8f45cf51_640..zip\n",
      "Converted ._a20983e5-4925-427f-a525-d2739548a59e+-+M.+Abdan+Alkhasbi_759.jfif to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._a20983e5-4925-427f-a525-d2739548a59e+-+M.+Abdan+Alkhasbi_759..zip\n",
      "Converted ._ADI REMANTO_100724_897.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._ADI REMANTO_100724_897.zip\n",
      "Converted ._AGUSTINUS TANNOS_150724_665.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._AGUSTINUS TANNOS_150724_665.zip\n",
      "Converted ._ANDANG TJAHJANTOK_150724_885.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._ANDANG TJAHJANTOK_150724_885.zip\n",
      "Converted ._ANDI HARTONO_wa150724_491.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._ANDI HARTONO_wa150724_491.zip\n",
      "Converted ._cecilia perubahan no rek_975.rar to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._cecilia perubahan no rek_975.zip\n",
      "Converted ._CHRISTIAN SETIAWAN DOLOKSARIBU_150224_924.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._CHRISTIAN SETIAWAN DOLOKSARIBU_150224_924.zip\n",
      "Converted ._CHRISTIAN SETIAWAN DOLOKSARIBU_150324_925.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._CHRISTIAN SETIAWAN DOLOKSARIBU_150324_925.zip\n",
      "Converted ._CHRISTIAN SETIAWAN DOLOKSARIBU_150424_926.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._CHRISTIAN SETIAWAN DOLOKSARIBU_150424_926.zip\n",
      "Converted ._DEA JANE SUNGKONO_150624_576.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._DEA JANE SUNGKONO_150624_576.zip\n",
      "Converted ._DEA JANE SUNGKONO_150724_577.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._DEA JANE SUNGKONO_150724_577.zip\n",
      "Converted ._DESSY ROSMARIA_100724_517.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._DESSY ROSMARIA_100724_517.zip\n",
      "Converted ._ERI SOSIALISMAN_150624_574.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._ERI SOSIALISMAN_150624_574.zip\n",
      "Converted ._ERIK AZARYA ERLAN_200724_561.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._ERIK AZARYA ERLAN_200724_561.zip\n",
      "Converted ._FADLI HAQIQI MAGHRIBI_150724_600.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._FADLI HAQIQI MAGHRIBI_150724_600.zip\n",
      "Converted ._faf6b70c-8af8-441a-9864-8d8c1b336bae_641.jfif to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._faf6b70c-8af8-441a-9864-8d8c1b336bae_641..zip\n",
      "Converted ._FANI SYAHRIAL R_250624_550.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._FANI SYAHRIAL R_250624_550.zip\n",
      "Converted ._FANI SYAHRIAL R_250724_551.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._FANI SYAHRIAL R_250724_551.zip\n",
      "Converted ._GONAWAN EFENDY_020724_542.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._GONAWAN EFENDY_020724_542.zip\n",
      "Converted ._HANDY PRADHITYA TJHAN_150724_883.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._HANDY PRADHITYA TJHAN_150724_883.zip\n",
      "Converted ._hartono golam autodebet_987.rar to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._hartono golam autodebet_987.zip\n",
      "Converted ._haru no hp_990.rar to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._haru no hp_990.zip\n",
      "Converted ._JENNI MONALISA NABABAN_150724_899.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._JENNI MONALISA NABABAN_150724_899.zip\n",
      "Converted ._KRISTIANA SATIO_100724_572.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._KRISTIANA SATIO_100724_572.zip\n",
      "Converted ._MARGANDATB SITUMORANG_150724_904.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._MARGANDATB SITUMORANG_150724_904.zip\n",
      "Converted ._NEW_REKENING_KORAN_ONLINE_323401019590537_2024-07-28_2024-07-29_00343994.pdf_429.crdownload to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._NEW_REKENING_KORAN_ONLINE_323401019590537_2024-07-28_2024-07-29_00343994.pdf_429.crdown.zip\n",
      "Converted ._NEW_REKENING_KORAN_ONLINE_738701011779538_2024-07-25_2024-07-25_00362082.pdf_820.crdownload to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._NEW_REKENING_KORAN_ONLINE_738701011779538_2024-07-25_2024-07-25_00362082.pdf_820.crdown.zip\n",
      "Converted ._NIKEN NOVIANTY RISDIANASARI_020624_543.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._NIKEN NOVIANTY RISDIANASARI_020624_543.zip\n",
      "Converted ._RIDO TANAIR_100724_888.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._RIDO TANAIR_100724_888.zip\n",
      "Converted ._RIKA ANDINI_150524_940.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._RIKA ANDINI_150524_940.zip\n",
      "Converted ._RIKA ANDINI_150624_941.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._RIKA ANDINI_150624_941.zip\n",
      "Converted ._RIKA ANDINI_150724_945.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._RIKA ANDINI_150724_945.zip\n",
      "Converted ._RMOCHAMAD GANDHANI_150724_534.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._RMOCHAMAD GANDHANI_150724_534.zip\n",
      "Converted ._RUDY YUWONO_plt150724_514.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._RUDY YUWONO_plt150724_514.zip\n",
      "Converted ._RUDY YUWONO_visa150724_513.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._RUDY YUWONO_visa150724_513.zip\n",
      "Converted ._SURYA PURNAMA TJENG_100724_485.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._SURYA PURNAMA TJENG_100724_485.zip\n",
      "Converted ._SYIFA ALAINA MARICAR_150624_563.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._SYIFA ALAINA MARICAR_150624_563.zip\n",
      "Converted ._SYIFA ALAINA MARICAR_150724_571.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._SYIFA ALAINA MARICAR_150724_571.zip\n",
      "Converted ._TEK SUYANTO_200724_508.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._TEK SUYANTO_200724_508.zip\n",
      "Converted ._THERESIA_150724_532.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._THERESIA_150724_532.zip\n",
      "Converted ._TITIN NURLAILA_170724_670.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._TITIN NURLAILA_170724_670.zip\n",
      "Converted ._TRI PANGESTU ADI NAGARA_170724_591.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._TRI PANGESTU ADI NAGARA_170724_591.zip\n",
      "Converted ._YUNITA SARI DEWI_150424_906.htm to D:\\Python2\\Attachment\\Report(6)\\__MACOSX\\Report(6)\\._YUNITA SARI DEWI_150424_906.zip\n",
      "Data from D:\\Python2\\Attachment\\Report(6)\\Report(6)\\Report.arx saved to CSV at D:\\Python2\\Attachment\\Report(6)_files_info.csv\n",
      "Extracted Report(7).zip to D:\\Python2\\Attachment\\Report(7)\n",
      "Converted 54204961a.jpeg_168.crdownload to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\54204961a.jpeg_168.crdown.zip\n",
      "Converted BBKHIT SULAWESI TENGGARA_0724_381.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\BBKHIT SULAWESI TENGGARA_0724_381.zip\n",
      "Converted DEWI CORRY_150724_403.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\DEWI CORRY_150724_403.zip\n",
      "Converted DEWI CORRY_150724_404.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\DEWI CORRY_150724_404.zip\n",
      "Converted IRVAN PANJAITAN_ptlt100724_405.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\IRVAN PANJAITAN_ptlt100724_405.zip\n",
      "Converted JUSRI_080724_398.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\JUSRI_080724_398.zip\n",
      "Converted LEDYANA CHRISTINE SUMITRO_170724_380.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\LEDYANA CHRISTINE SUMITRO_170724_380.zip\n",
      "Converted NENO RIANA_080724_378.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\NENO RIANA_080724_378.zip\n",
      "Converted OENTOENG SUBAGIO_jcb100724_410.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\OENTOENG SUBAGIO_jcb100724_410.zip\n",
      "Converted OENTOENG SUBAGIO_PLT100724_406.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\OENTOENG SUBAGIO_PLT100724_406.zip\n",
      "Converted RUSWANTORO WIDJAJA_150724_400.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\RUSWANTORO WIDJAJA_150724_400.zip\n",
      "Converted SITI BAINAH_080724_34.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\SITI BAINAH_080724_34.zip\n",
      "Converted SRI HARJA_150724_401.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\SRI HARJA_150724_401.zip\n",
      "Converted SUDIRMAN_080724_397.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\SUDIRMAN_080724_397.zip\n",
      "Converted SUSANTO_170724_399.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\SUSANTO_170724_399.zip\n",
      "Converted TINA ERINDA FEBRIANI_170724_407.htm to D:\\Python2\\Attachment\\Report(7)\\Report(7)\\TINA ERINDA FEBRIANI_170724_407.zip\n",
      "Converted ._54204961a.jpeg_168.crdownload to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._54204961a.jpeg_168.crdown.zip\n",
      "Converted ._BBKHIT SULAWESI TENGGARA_0724_381.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._BBKHIT SULAWESI TENGGARA_0724_381.zip\n",
      "Converted ._DEWI CORRY_150724_403.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._DEWI CORRY_150724_403.zip\n",
      "Converted ._DEWI CORRY_150724_404.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._DEWI CORRY_150724_404.zip\n",
      "Converted ._IRVAN PANJAITAN_ptlt100724_405.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._IRVAN PANJAITAN_ptlt100724_405.zip\n",
      "Converted ._JUSRI_080724_398.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._JUSRI_080724_398.zip\n",
      "Converted ._LEDYANA CHRISTINE SUMITRO_170724_380.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._LEDYANA CHRISTINE SUMITRO_170724_380.zip\n",
      "Converted ._NENO RIANA_080724_378.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._NENO RIANA_080724_378.zip\n",
      "Converted ._OENTOENG SUBAGIO_jcb100724_410.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._OENTOENG SUBAGIO_jcb100724_410.zip\n",
      "Converted ._OENTOENG SUBAGIO_PLT100724_406.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._OENTOENG SUBAGIO_PLT100724_406.zip\n",
      "Converted ._RUSWANTORO WIDJAJA_150724_400.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._RUSWANTORO WIDJAJA_150724_400.zip\n",
      "Converted ._SITI BAINAH_080724_34.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._SITI BAINAH_080724_34.zip\n",
      "Converted ._SRI HARJA_150724_401.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._SRI HARJA_150724_401.zip\n",
      "Converted ._SUDIRMAN_080724_397.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._SUDIRMAN_080724_397.zip\n",
      "Converted ._SUSANTO_170724_399.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._SUSANTO_170724_399.zip\n",
      "Converted ._TINA ERINDA FEBRIANI_170724_407.htm to D:\\Python2\\Attachment\\Report(7)\\__MACOSX\\Report(7)\\._TINA ERINDA FEBRIANI_170724_407.zip\n",
      "Data from D:\\Python2\\Attachment\\Report(7)\\Report(7)\\Report.arx saved to CSV at D:\\Python2\\Attachment\\Report(7)_files_info.csv\n",
      "Extracted to upload on bridrive_8 aug.zip to D:\\Python2\\Attachment\\to upload on bridrive_8 aug\n",
      "No 'ReportTest.arx' found in D:\\Python2\\Attachment\\to upload on bridrive_8 aug\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import rarfile  # pip install rarfile\n",
    "import pandas as pd\n",
    "\n",
    "def extract_and_process_files(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "\n",
    "        # Extract the big zip file\n",
    "        if filename.endswith(\".zip\"):\n",
    "            extract_path = os.path.join(directory, filename[:-4])\n",
    "            with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_path)\n",
    "                print(f\"Extracted {filename} to {extract_path}\")\n",
    "\n",
    "            # Convert specific file types to zip within the extracted folder\n",
    "            convert_files_to_zip(extract_path)\n",
    "\n",
    "            # Process the extracted folder to find 'ReportTest.arx' and create the DataFrame\n",
    "            report_file_path = find_report_file(extract_path)\n",
    "            if report_file_path:\n",
    "                df = create_dataframe_from_file(report_file_path, extract_path)\n",
    "                csv_path = os.path.join(directory, filename[:-4] + '_files_info.csv')\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                print(f\"Data from {report_file_path} saved to CSV at {csv_path}\")\n",
    "            else:\n",
    "                print(f\"No 'ReportTest.arx' found in {extract_path}\")\n",
    "\n",
    "def convert_files_to_zip(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith((\".txt\", \".rtp\", \".tif\", \".rar\",\".rptdesign\",\".js\",\".jfif\",\".crdownload\",\".heic\",\".htm\")):\n",
    "                file_path = os.path.join(root, file)\n",
    "                new_zip_path = file_path[:-4] + \".zip\"\n",
    "                with zipfile.ZipFile(new_zip_path, 'w') as zip_ref:\n",
    "                    zip_ref.write(file_path, file)\n",
    "                os.remove(file_path)  # Optionally remove the original file\n",
    "                print(f\"Converted {file} to {new_zip_path}\")\n",
    "\n",
    "def find_report_file(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == 'Report.arx':\n",
    "                return os.path.join(root, file)\n",
    "    return None\n",
    "\n",
    "def create_dataframe_from_file(file_path, extract_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    titles = []\n",
    "    descriptions = []\n",
    "    version_data = []\n",
    "    path_on_client = []\n",
    "    first_publish_location_ids = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"DATA\"):\n",
    "            parts = line.strip().split('\"')\n",
    "            ticket_number = parts[1].strip()\n",
    "            file_name = parts[3].strip().partition(' ')[2]  # Extracting everything after \"1 \"\n",
    "\n",
    "            # Check if the file was converted to zip\n",
    "            original_file_path = os.path.join(extract_path, file_name)\n",
    "            zip_file_path = original_file_path[:-4] + \".zip\"\n",
    "            if os.path.exists(zip_file_path):\n",
    "                full_path = zip_file_path\n",
    "            else:\n",
    "                full_path = original_file_path\n",
    "\n",
    "            titles.append(file_name)\n",
    "            descriptions.append(\"\")\n",
    "            version_data.append(full_path)\n",
    "            path_on_client.append(full_path)\n",
    "            first_publish_location_ids.append(ticket_number)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Description': descriptions,\n",
    "        'VersionData': version_data,\n",
    "        'PathOnClient': path_on_client,\n",
    "        'FirstPublishLocationId': first_publish_location_ids\n",
    "    })\n",
    "\n",
    "directory_path = r\"D:\\Python2\\Attachment\"\n",
    "extract_and_process_files(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted ReportTest.zip to D:\\Salesforce\\archive\\dataquality\\Tool for attachments\\ReportTest\n",
      "Data from D:\\Salesforce\\archive\\dataquality\\Tool for attachments\\ReportTest\\ReportTest.arx saved to CSV at D:\\Salesforce\\archive\\dataquality\\Tool for attachments\\ReportTest_files_info.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import rarfile  # pip install rarfile\n",
    "import pandas as pd\n",
    "\n",
    "def extract_and_process_files(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        extract_path = os.path.join(directory, filename[:-4]) \n",
    "\n",
    "        if filename.endswith(\".zip\"):\n",
    "            with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_path)\n",
    "                print(f\"Extracted {filename} to {extract_path}\")\n",
    "        elif filename.endswith(\".rar\"):\n",
    "            with rarfile.RarFile(filepath, 'r') as rar_ref:\n",
    "                rar_ref.extractall(extract_path)\n",
    "                print(f\"Extracted {filename} to {extract_path}\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        report_file_path = find_report_file(extract_path)\n",
    "        if report_file_path:\n",
    "            df = create_dataframe_from_file(report_file_path, extract_path)\n",
    "            csv_path = os.path.join(directory, filename[:-4] + '_files_info.csv')\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(f\"Data from {report_file_path} saved to CSV at {csv_path}\")\n",
    "        else:\n",
    "            print(f\"No 'ReportTest.arx' found in {extract_path}\")\n",
    "\n",
    "def find_report_file(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == 'ReportTest.arx':\n",
    "                return os.path.join(root, file)\n",
    "    return None\n",
    "\n",
    "def create_dataframe_from_file(file_path, extract_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    titles = []\n",
    "    descriptions = []\n",
    "    version_data = []\n",
    "    first_publish_location_ids = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"DATA\"):\n",
    "            parts = line.strip().split('\"')\n",
    "            ticket_number = parts[1].strip()\n",
    "            file_name = parts[3].strip().partition(' ')[2]  # Extracting everything after \"1 \"\n",
    "\n",
    "            full_path = os.path.join(extract_path, file_name)\n",
    "\n",
    "            titles.append(file_name)\n",
    "            descriptions.append(\"\")\n",
    "            version_data.append(full_path)\n",
    "            first_publish_location_ids.append(ticket_number)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Description': descriptions,\n",
    "        'VersionData': version_data,\n",
    "        'PathOnClient': version_data,  # New column added here\n",
    "        'FirstPublishLocationId': first_publish_location_ids\n",
    "    })\n",
    "\n",
    "directory_path = r'D:\\Salesforce\\archive\\dataquality\\Tool for attachments'\n",
    "extract_and_process_files(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\attachment\\Report.arx saved to CSV at C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\attachment\\Report.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_dataframe_from_file(file_path, extract_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    titles = []\n",
    "    descriptions = []\n",
    "    version_data = []\n",
    "    first_publish_location_ids = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"DATA\"):\n",
    "            parts = line.strip().split('\"')\n",
    "            ticket_number = parts[1].strip()\n",
    "            file_name = parts[3].strip().partition(' ')[2]  # Extracting everything after \"1 \"\n",
    "\n",
    "            full_path = os.path.join(r'E:\\Attachment\\report1', file_name)\n",
    "\n",
    "            titles.append(file_name)\n",
    "            descriptions.append(\"\")\n",
    "            version_data.append(full_path)\n",
    "            first_publish_location_ids.append(ticket_number)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Description': descriptions,\n",
    "        'VersionData': version_data,\n",
    "        'PathOnClient': version_data,  # New column added here\n",
    "        'FirstPublishLocationId': first_publish_location_ids\n",
    "    })\n",
    "\n",
    "# Assume this is the path to the report file you uploaded\n",
    "report_file_path = r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\attachment\\Report.arx\"\n",
    "# Create dataframe\n",
    "df = create_dataframe_from_file(report_file_path, 'E:\\\\Attachment\\\\report1')\n",
    "# Save to CSV\n",
    "csv_path = r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\attachment\\Report.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Data from {report_file_path} saved to CSV at {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to create copied 1000 ine\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "path=r\"C:\\Users\\maste\\Downloads\\bricare\\file_for_attachment.csv\"\n",
    "df=pd.read_csv(path)\n",
    "\n",
    "df = pd.concat([df] * 1000, ignore_index=True)\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to change the column FirstPublishLocationId with all values in ID column taken from case ID in salesforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'FirstPublishLocationId' column has been replaced with the 'ID' column values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>VersionData</th>\n",
       "      <th>PathOnClient</th>\n",
       "      <th>FirstPublishLocationId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>attachment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf</td>\n",
       "      <td>/Users/ikawahyuni/dataquality/large_dummy_file...</td>\n",
       "      <td>500MR00000449KLYAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>attachment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf</td>\n",
       "      <td>/Users/ikawahyuni/dataquality/large_dummy_file...</td>\n",
       "      <td>500MR00000449KMYAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>attachment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf</td>\n",
       "      <td>/Users/ikawahyuni/dataquality/large_dummy_file...</td>\n",
       "      <td>500MR00000449KNYAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>attachment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf</td>\n",
       "      <td>/Users/ikawahyuni/dataquality/large_dummy_file...</td>\n",
       "      <td>500MR00000449KOYAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>attachment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf</td>\n",
       "      <td>/Users/ikawahyuni/dataquality/large_dummy_file...</td>\n",
       "      <td>500MR00000449KPYAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>attachment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf</td>\n",
       "      <td>/Users/ikawahyuni/dataquality/large_dummy_file...</td>\n",
       "      <td>500MR00000449LtYAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>attachment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf</td>\n",
       "      <td>/Users/ikawahyuni/dataquality/large_dummy_file...</td>\n",
       "      <td>500MR00000449LuYAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>attachment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf</td>\n",
       "      <td>/Users/ikawahyuni/dataquality/large_dummy_file...</td>\n",
       "      <td>500MR00000449LvYAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>attachment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf</td>\n",
       "      <td>/Users/ikawahyuni/dataquality/large_dummy_file...</td>\n",
       "      <td>500MR00000449LwYAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>attachment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf</td>\n",
       "      <td>/Users/ikawahyuni/dataquality/large_dummy_file...</td>\n",
       "      <td>500MR00000449LxYAI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Title  Description                              VersionData  \\\n",
       "900  attachment          NaN  C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf   \n",
       "901  attachment          NaN  C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf   \n",
       "902  attachment          NaN  C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf   \n",
       "903  attachment          NaN  C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf   \n",
       "904  attachment          NaN  C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf   \n",
       "..          ...          ...                                      ...   \n",
       "995  attachment          NaN  C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf   \n",
       "996  attachment          NaN  C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf   \n",
       "997  attachment          NaN  C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf   \n",
       "998  attachment          NaN  C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf   \n",
       "999  attachment          NaN  C:\\Users\\lenovo\\Downloads\\dummy15mb.pdf   \n",
       "\n",
       "                                          PathOnClient FirstPublishLocationId  \n",
       "900  /Users/ikawahyuni/dataquality/large_dummy_file...     500MR00000449KLYAY  \n",
       "901  /Users/ikawahyuni/dataquality/large_dummy_file...     500MR00000449KMYAY  \n",
       "902  /Users/ikawahyuni/dataquality/large_dummy_file...     500MR00000449KNYAY  \n",
       "903  /Users/ikawahyuni/dataquality/large_dummy_file...     500MR00000449KOYAY  \n",
       "904  /Users/ikawahyuni/dataquality/large_dummy_file...     500MR00000449KPYAY  \n",
       "..                                                 ...                    ...  \n",
       "995  /Users/ikawahyuni/dataquality/large_dummy_file...     500MR00000449LtYAI  \n",
       "996  /Users/ikawahyuni/dataquality/large_dummy_file...     500MR00000449LuYAI  \n",
       "997  /Users/ikawahyuni/dataquality/large_dummy_file...     500MR00000449LvYAI  \n",
       "998  /Users/ikawahyuni/dataquality/large_dummy_file...     500MR00000449LwYAI  \n",
       "999  /Users/ikawahyuni/dataquality/large_dummy_file...     500MR00000449LxYAI  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df1 = pd.read_csv(r\"C:\\Users\\maste\\Downloads\\bricare\\file_for_attachment.csv\")  # Assuming this file contains the columns Title, Description, VersionData, PathOnClient, FirstPublishLocationId\n",
    "df2 = pd.read_csv(r\"C:\\Users\\maste\\Downloads\\bricare\\extract_case_id_1000.csv\")  # Assuming this file contains the column ID\n",
    "\n",
    "# Check if both DataFrames have the same number of rows\n",
    "if len(df1) != len(df2):\n",
    "    raise ValueError(\"The number of rows in both files must be the same\")\n",
    "\n",
    "# Replace the 'FirstPublishLocationId' column in df1 with the 'ID' column from df2\n",
    "df1['FirstPublishLocationId'] = df2['ID']\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "# df1.to_csv('modified_file.csv', index=False)\n",
    "\n",
    "print(\"The 'FirstPublishLocationId' column has been replaced with the 'ID' column values.\")\n",
    "\n",
    "df1.iloc[900:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File split_file_1.csv created with rows from 0 to 100\n",
      "File split_file_2.csv created with rows from 100 to 200\n",
      "File split_file_3.csv created with rows from 200 to 300\n",
      "File split_file_4.csv created with rows from 300 to 400\n",
      "File split_file_5.csv created with rows from 400 to 500\n",
      "Files created successfully.\n"
     ]
    }
   ],
   "source": [
    "## Slice into 5 files\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\bricare\\file_for_attachment.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Number of rows per split file\n",
    "rows_per_file = 100\n",
    "\n",
    "# Create 5 files with 200 rows each\n",
    "for i in range(5):\n",
    "    start_row = i * rows_per_file\n",
    "    end_row = (i + 1) * rows_per_file\n",
    "    split_df = df.iloc[start_row:end_row]\n",
    "    split_file_path = f'split_file_{i + 1}.csv'\n",
    "    split_df.to_csv(split_file_path, index=False)\n",
    "    print(f'File {split_file_path} created with rows from {start_row} to {end_row}')\n",
    "\n",
    "print('Files created successfully.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified file saved at: C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\Report csv\\Report csv\\Report8.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\Report csv\\report7.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Replace 'report1' with 'Report2' in the 'VersionData' and 'PathOnClient' columns\n",
    "data['VersionData'] = data['VersionData'].str.replace('report1', 'Report8')\n",
    "data['PathOnClient'] = data['PathOnClient'].str.replace('report1', 'Report8')\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "modified_file_path = r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\Report csv\\Report csv\\Report8.csv\"\n",
    "data.to_csv(modified_file_path, index=False)\n",
    "\n",
    "# Provide the path to the modified file\n",
    "print(f'Modified file saved at: {modified_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified file saved at: C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\Report csv\\Report csv\\Modified_Report2.csv\n",
      "Modified file saved at: C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\Report csv\\Report csv\\Modified_Report3.csv\n",
      "Modified file saved at: C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\Report csv\\Report csv\\Modified_Report4.csv\n",
      "Modified file saved at: C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\Report csv\\Report csv\\Modified_Report5.csv\n",
      "Modified file saved at: C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\Report csv\\Report csv\\Modified_Report6.csv\n",
      "Modified file saved at: C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\Report csv\\Report csv\\Modified_Report7.csv\n",
      "Modified file saved at: C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\Report csv\\Report csv\\Modified_Report8.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder containing the CSV files\n",
    "folder_path = r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\server\\Report csv\\Report csv\"  \n",
    "\n",
    "# Loop through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # Replace drive 'D' with 'E' in the 'VersionData' and 'PathOnClient' columns\n",
    "        data['VersionData'] = data['VersionData'].str.replace('D:', 'E:')\n",
    "        data['PathOnClient'] = data['PathOnClient'].str.replace('D:', 'E:')\n",
    "        \n",
    "        # Save the modified DataFrame to a new CSV file\n",
    "        modified_file_path = os.path.join(folder_path, f'Modified_{filename}')\n",
    "        data.to_csv(modified_file_path, index=False)\n",
    "\n",
    "        print(f'Modified file saved at: {modified_file_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Python2\\\\Attachment\\\\attachments_log\\\\log_report8\\\\error080524022045731_done.csv'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r\"D:\\Python2\\Attachment\\attachments_log\\log_report8\\error080524022045731.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the new folder path\n",
    "new_folder_path = \"D:\\Python2\\Attachment\\Report(7)\\Report(7)\"\n",
    "\n",
    "# Update the VERSIONDATA and PATHONCLIENT columns\n",
    "# df['VERSIONDATA'] = df['VERSIONDATA'].apply(lambda x: new_folder_path + x.split('Report(4)')[-1].replace('/', '\\\\'))\n",
    "# df['PATHONCLIENT'] = df['PATHONCLIENT'].apply(lambda x: new_folder_path + x.split('Report(4)')[-1].replace('/', '\\\\'))\n",
    "\n",
    "df['VersionData'] = df['VersionData'].apply(lambda x: os.path.join(new_folder_path, os.path.basename(x)).replace('/', '\\\\'))\n",
    "df['PathOnClient'] = df['PathOnClient'].apply(lambda x: os.path.join(new_folder_path, os.path.basename(x)).replace('/', '\\\\'))\n",
    "\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_path = r\"D:\\Python2\\Attachment\\attachments_log\\log_report8\\error080524022045731_done.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Provide the path to the updated file\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting into ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\SITI BAINAH_080724_34.htm\n",
      "Successfully zipped: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\ABSENSI MANUAL NINIK_127.odt\n",
      "Successfully zipped: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\Invoice Blibli I Wayan_138.csv\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\54204961a.jpeg_168.crdownload\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\NENO RIANA_080724_378.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\LEDYANA CHRISTINE SUMITRO_170724_380.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\BBKHIT SULAWESI TENGGARA_0724_381.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\SUDIRMAN_080724_397.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\JUSRI_080724_398.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\SUSANTO_170724_399.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\RUSWANTORO WIDJAJA_150724_400.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\SRI HARJA_150724_401.htm\n",
      "Successfully zipped: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\TTB000054221593_402.doc\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\DEWI CORRY_150724_403.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\DEWI CORRY_150724_404.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\IRVAN PANJAITAN_ptlt100724_405.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\OENTOENG SUBAGIO_PLT100724_406.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\TINA ERINDA FEBRIANI_170724_407.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(7)\\Report(7)\\OENTOENG SUBAGIO_jcb100724_410.htm\n",
      "Updated CSV file saved as: D:\\Python2\\Attachment\\attachments_log\\log_report8\\error081224021733461_done2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r\"D:\\Python2\\Attachment\\attachments_log\\log_report8\\error081224021733461.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Get the file title and the directory from VERSIONDATA\n",
    "    title = row['TITLE']\n",
    "    version_data_path = row['VERSIONDATA']\n",
    "    \n",
    "    # Ensure both TITLE and VERSIONDATA are not null\n",
    "    if pd.notnull(title) and pd.notnull(version_data_path):\n",
    "        # Get the directory path from VERSIONDATA\n",
    "        dir_path = os.path.dirname(version_data_path)\n",
    "        # Define the full file path\n",
    "        full_file_path = os.path.join(dir_path, title)\n",
    "        \n",
    "        # Define the ZIP file path\n",
    "        zip_file_path = full_file_path.replace(os.path.splitext(title)[1], '.zip')\n",
    "        \n",
    "        try:\n",
    "            # Create the ZIP file in the same directory without deleting the original file\n",
    "            with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
    "                zipf.write(full_file_path, title)\n",
    "            print(f\"Successfully zipped: {full_file_path}\")\n",
    "            \n",
    "            # Update the VERSIONDATA and PATHONCLIENT columns with the new ZIP file path\n",
    "            df.at[index, 'VERSIONDATA'] = zip_file_path\n",
    "            df.at[index, 'PATHONCLIENT'] = zip_file_path\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {full_file_path}\")\n",
    "\n",
    "# Define the new file name by adding \"_done\" to the original file name\n",
    "done_file_path = file_path.replace('.csv', '_done2.csv')\n",
    "\n",
    "# Save the updated DataFrame to the new CSV file\n",
    "df.to_csv(done_file_path, index=False)\n",
    "\n",
    "# Output the path to the new CSV file\n",
    "print(f\"Updated CSV file saved as: {done_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting into ZIP for files without extentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\20240727_231535_160.heic\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\NEW_REKENING_KORAN_ONLINE_323401019590537_2024-07-28_2024-07-29_00343994.pdf_429.crdownload\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\SURYA PURNAMA TJENG_100724_485.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\ANDI HARTONO_wa150724_491.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\TEK SUYANTO_200724_508.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RUDY YUWONO_visa150724_513.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RUDY YUWONO_plt150724_514.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\DESSY ROSMARIA_100724_517.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\THERESIA_150724_532.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RMOCHAMAD GANDHANI_150724_534.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\GONAWAN EFENDY_020724_542.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\NIKEN NOVIANTY RISDIANASARI_020624_543.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\FANI SYAHRIAL R_250624_550.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\FANI SYAHRIAL R_250724_551.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\ERIK AZARYA ERLAN_200724_561.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\SYIFA ALAINA MARICAR_150624_563.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\SYIFA ALAINA MARICAR_150724_571.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\KRISTIANA SATIO_100724_572.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\ERI SOSIALISMAN_150624_574.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\DEA JANE SUNGKONO_150624_576.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\DEA JANE SUNGKONO_150724_577.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\TRI PANGESTU ADI NAGARA_170724_591.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\FADLI HAQIQI MAGHRIBI_150724_600.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\6e929343-c3a9-4de4-b96f-ba7c8f45cf51_640.jfif\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\faf6b70c-8af8-441a-9864-8d8c1b336bae_641.jfif\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\AGUSTINUS TANNOS_150724_665.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\TITIN NURLAILA_170724_670.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\a20983e5-4925-427f-a525-d2739548a59e+-+M.+Abdan+Alkhasbi_759.jfif\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\NEW_REKENING_KORAN_ONLINE_738701011779538_2024-07-25_2024-07-25_00362082.pdf_820.crdownload\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\HANDY PRADHITYA TJHAN_150724_883.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\ANDANG TJAHJANTOK_150724_885.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RIDO TANAIR_100724_888.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\ADI REMANTO_100724_897.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\JENNI MONALISA NABABAN_150724_899.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\MARGANDATB SITUMORANG_150724_904.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\YUNITA SARI DEWI_150424_906.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\CHRISTIAN SETIAWAN DOLOKSARIBU_150224_924.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\CHRISTIAN SETIAWAN DOLOKSARIBU_150324_925.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\CHRISTIAN SETIAWAN DOLOKSARIBU_150424_926.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RIKA ANDINI_150524_940.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RIKA ANDINI_150624_941.htm\n",
      "File not found: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\RIKA ANDINI_150724_945.htm\n",
      "Successfully zipped: D:\\Python2\\Attachment\\Report(6)\\Report(6)\\image-1545708299631195_974.tmp\n",
      "Updated CSV file saved as: D:\\Python2\\Attachment\\attachments_log\\log_report7\\error081224023217824_done4.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r\"D:\\Python2\\Attachment\\attachments_log\\log_report7\\error081224023217824.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    title = row.get('TITLE', None)\n",
    "    version_data_path = row.get('VERSIONDATA', None)\n",
    "    \n",
    "    if pd.notnull(title) and pd.notnull(version_data_path):\n",
    "        dir_path = os.path.dirname(version_data_path)\n",
    "        full_file_path = os.path.join(dir_path, title)\n",
    "        \n",
    "        # Check if the file exists\n",
    "        if os.path.exists(full_file_path):\n",
    "            # Handle files without an extension\n",
    "            if not os.path.splitext(title)[1]:\n",
    "                temp_file_path = full_file_path + '.tmp'\n",
    "                shutil.copy(full_file_path, temp_file_path)\n",
    "                \n",
    "                # Zip the file with the temporary extension\n",
    "                zip_file_path = temp_file_path.replace('.tmp', '.zip')\n",
    "                \n",
    "                try:\n",
    "                    with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
    "                        zipf.write(temp_file_path, os.path.basename(temp_file_path))\n",
    "                    print(f\"Successfully zipped: {temp_file_path}\")\n",
    "                    \n",
    "                    # Update the DataFrame with the new ZIP file path\n",
    "                    df.at[index, 'VERSIONDATA'] = zip_file_path\n",
    "                    df.at[index, 'PATHONCLIENT'] = zip_file_path\n",
    "                    \n",
    "                    # Clean up the temporary file\n",
    "                    os.remove(temp_file_path)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error zipping file {temp_file_path}: {str(e)}\")\n",
    "            else:\n",
    "                # If the file has an extension, handle it normally\n",
    "                zip_file_path = full_file_path.replace(os.path.splitext(title)[1], '.zip')\n",
    "                \n",
    "                try:\n",
    "                    with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
    "                        zipf.write(full_file_path, title)\n",
    "                    print(f\"Successfully zipped: {full_file_path}\")\n",
    "                    \n",
    "                    # Update the DataFrame with the new ZIP file path\n",
    "                    df.at[index, 'VERSIONDATA'] = zip_file_path\n",
    "                    df.at[index, 'PATHONCLIENT'] = zip_file_path\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error zipping file {full_file_path}: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"File not found: {full_file_path}\")\n",
    "\n",
    "# Define the new file name by adding \"_done\" to the original file name\n",
    "done_file_path = file_path.replace('.csv', '_done4.csv')\n",
    "\n",
    "# Save the updated DataFrame to the new CSV file\n",
    "df.to_csv(done_file_path, index=False)\n",
    "\n",
    "# Output the path to the new CSV file\n",
    "print(f\"Updated CSV file saved as: {done_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>VERSIONDATA</th>\n",
       "      <th>PATHONCLIENT</th>\n",
       "      <th>FIRSTPUBLISHLOCATIONID</th>\n",
       "      <th>ERROR</th>\n",
       "      <th>ERROR.1</th>\n",
       "      <th>ERROR2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image-1206599770477098_296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:\\Python2\\Attachment\\Report(2)\\Report(2)\\imag...</td>\n",
       "      <td>D:\\Python2\\Attachment\\Report(2)\\Report(2)\\imag...</td>\n",
       "      <td>TTB000053927901</td>\n",
       "      <td>Error converting value to correct data type: C...</td>\n",
       "      <td>Error converting value to correct data type: C...</td>\n",
       "      <td>Error converting value to correct data type: C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        TITLE  DESCRIPTION  \\\n",
       "0  image-1206599770477098_296          NaN   \n",
       "\n",
       "                                         VERSIONDATA  \\\n",
       "0  D:\\Python2\\Attachment\\Report(2)\\Report(2)\\imag...   \n",
       "\n",
       "                                        PATHONCLIENT FIRSTPUBLISHLOCATIONID  \\\n",
       "0  D:\\Python2\\Attachment\\Report(2)\\Report(2)\\imag...        TTB000053927901   \n",
       "\n",
       "                                               ERROR  \\\n",
       "0  Error converting value to correct data type: C...   \n",
       "\n",
       "                                             ERROR.1  \\\n",
       "0  Error converting value to correct data type: C...   \n",
       "\n",
       "                                              ERROR2  \n",
       "0  Error converting value to correct data type: C...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path=r\"D:\\Python2\\Attachment\\attachments_log\\log_report3\\error081224104300248.csv\"\n",
    "\n",
    "df=pd.read_csv(path)\n",
    "# df.to_csv(path, index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To attach files to cases aftyer closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully at: C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\extractfile_alex7_done.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "file_1_path = r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\extractfile_alex7_from_file.csv\"\n",
    "file_2_path = r\"C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\extract_content_doc_link.csv\"\n",
    "\n",
    "# Read the files into pandas dataframes\n",
    "df_extract = pd.read_csv(file_1_path)\n",
    "df_content_doc_link = pd.read_csv(file_2_path)\n",
    "\n",
    "# Merging the two dataframes based on the 'CONTENTDOCUMENTID' column\n",
    "df_merged = pd.merge(df_extract, df_content_doc_link[['CONTENTDOCUMENTID', 'ID', 'LINKEDENTITYID']], on='CONTENTDOCUMENTID', how='left')\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "output_file_path = r'C:\\Users\\maste\\Downloads\\dataloader_v60.0.2\\extractfile_alex7_done.csv'\n",
    "df_merged.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"File saved successfully at:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all Report Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined file saved as D:\\Python2\\cekcek\\Report csv\\combined_report.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the directory where your files are located\n",
    "folder_path = r\"D:\\Python2\\cekcek\\Report csv\"\n",
    "\n",
    "# Initialize an empty list to hold dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through all CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(os.path.join(folder_path, filename))\n",
    "        \n",
    "        # Add the 'source_file' column\n",
    "        df['source_file'] = filename\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list into one dataframe\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "output_file = 'D:\\Python2\\cekcek\\Report csv\\combined_report.csv'\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Combined file saved as {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
